任务：
人体姿态序列分类

数据集：
放在data文件夹下
使用data/train里面的数据训练模型
使用data/test里面的数据汇报结果

效果评估：
使用data/test里面5类样本的平均识别率作为指标

提交作业：
暂定7月31号
代码放github（包含如何运行等的readme）+ PPT说明原理改进效果等

----------------------------------------------------------------TIPs---------------------------------------------------------------------
数据可视化
使用show.py文件，可以直观看到每个sample的物理意义：双人交互动作或者单人动作，即一段双人(单人)姿态随时间变化的序列
每个sample为一个numpy数组，大小为(1,3,128,17,2)，代表batchsize为1，坐标为3维，128帧，17个关节点，2个人
实际上，只有2维坐标信息，即sample[:,1, :, :, :]可赋值为0；sample[:, :, :, :, 1] 为0时代表单人动作，即另一个人的动作是缺失的

难点
1. CNN/RNN/GCN/Transformer都适用于该任务，如何取得最好效果
2. 如何处理样本量不足的情况：生成或者数据增强都值得尝试

参考资料
https://github.com/hamlinzheng/Awesome-Skeleton-based-Action-Recognition
